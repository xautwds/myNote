3/11日
URL:协议（https） + 域名（www.baidu.com：443） + 资源

多级域名 + 多级资源列表

://分割符
/(代表根目录或者是目录分割符)

.com  .org (顶级域名)  .com公司和企业  
baidu(一级域名)
zhidao.baidu.com  同一个域名内而已有多个子服务（二级域名）

每一个链接都有唯一的资源 百度把所有超链接串联在一起

编码解码需要相互对应

www万维网协议

缩略图靠对应的软件实现.
打开方式就是选择可以支持打开的解码格式.

周知端口：只是一个默认端口。

uri和url
URL(统一资源定位符) , 在服务器的搜索资源的信息位置一定，但内容未必是这个目录.

ipdb??  wget??!

cookie 保存数据在本地，保存客户端信息
淘宝为何能直接使用支付宝，通过session保存信息(session必须和长连接必须学会)

作业：当前http常见状态码有什么？

点分十进制？

http1.0  和 http1.1 对比？？  持续连接是什么意思？长连接和短连接 查询

HTTP1.1 支持数据包的分块传输  支持状态 

DNS先访问本地缓存，找不到再递归到上层；可以通过更改配置，改变百度的寻找到的IP
localhost通过DNS本地配置成127.0.0.1


C复习:
int ar[5] = {1,2,3,4,5} ;
int *ptr = (int *)(&ar + 1) ;
*(ptr - 1) = 5 ;   //数组长度+ 1


int ar[5] = {0} ;
memset(ar , 0 , sizeof(ar)) ;
bzero() ;

int *cr[5] = {NULL} ;

int ar[5] = {0} ;  //ar为一维数组
int (*cr)[5] = &ar ; //&ar使其上升一个维度   &ar + 1使得整个数组+1

int (*fun)(void * a) ; 
int func(void * a){} 
fun = func ;

C是强类型语言，类型匹配很重要

NULL个人理解就是一个宏定义 == 0

编译器有些情况进行弱检查  比如0 == NULL   
	int * p = 0 ;
	int * q = NULL ;
	int *r = 10 ;
对p的弱检查

3/19日
一台服务器最多能链接多少个客户端？？
TCP中close和shutdown的关闭方式不同在哪里？？

socket返回的描述符fd只有本地意义，与open返回的fd描述符对于内核一致，只对于本机有效。
因为标准输入输出一般为0 ， 1  ， 2 ， 所以socket一般不会创建成1

bind叫做命名函数，给创建的socket起名，把IP和端口与socket进行具有通信的功能。

listen(fd , 5) //2.62以后只代表已经完全握手成功的fd ， 5代表幻数 ， 并不代表只有5.

网络模型，除了异步模型其他都是同步模型 ，同步里面有阻塞和非阻塞。  //五种？？  阻塞非阻塞，异步同步，IO复用
阻塞是，用户进程调用系统调用，内核资源没有准备好，帮助进程挂起，等到某时间资源好了，再唤起进程。对于进程来说，自己就像被阻塞了。
内核通过合适的时机，再将进程调CPU执行

非阻塞，产生系统调用，内核资源没有准备好，但是内核不帮忙挂起（重点），返回错误，只能用户自己去多次查询。内核不帮忙挂起，用户有自己询问的权利

异步，产生系统调用，内核资源没有准备好，但是内核不帮忙挂起，数据拷贝完之后，再通知你。  //自查(github)
//aio_read  , aio_write

每个socket有自己的读写缓冲，netstat可以查看read，send的buff ，/proc（核心目录 , 内核参数可以调整）/sys/
send的缓冲区就可以用在socket发送数据的滑动窗口的缓冲。

IO复用Kqueue ， pselect ， select ， poll ， epoll ，/dev/poll都要了解

/dev/poll:Solaris上名为/dev/poll的特殊文件提供了一个可扩展的轮询大量描述符的方法。select和poll存在的一个问题是，每次调用它们都得传递待查询的文件描述符。
轮询设备能在调用之间维持状态，因此轮询进程可以预先设置好待查询描述符的列表，然后进入一个循环等待事件发生，每次循环回来时不必再次设置该列表。

pselect的time超时精度比select高，而且设置屏蔽字，当调用pselect时，屏蔽sigmask里面的信号，返回时恢复。1

kqueue是free BSD中实现的IO复用机制，类似于epoll() ， kquece()产生描述符，kevent() 进行事件的添加与删除。其中 kqueue 对 AIO，POSIX 的异步 IO 系列的支持，
是异步行为完成通知机制之一。int kevent(int kq (文件描述符FD), const struct kevent *changelist(需要添加或者修改的事件), 
int nchanges, struct kevent *eventlist (返回的事件), int nevents, const struct timespec *timeout); 避免轮训，使用回调

select优点：可以同时处理多个描述符，可以同时处理可读可写，select各个参数(最后一个)的含义. 可以告知用户进程那些fd就绪.解放了read单个读取
比如多个read都需要线性等待，而select直接告知可以读取的fd

(最后一个参数)NULL == 死等(阻塞)  0==查询(非阻塞)  200==等待（万一出现100毫秒怎么办？？）100返回  就绪就应该马上返回
如果超过200毫秒，就以timeout错误返回.   -1== 会永远等待？？
缺点：上限1024（软），需要自己去遍历那些就绪，用户态拷贝到内核态，再重内核态返回到用户态。每次select产生两次遍历调用。
用户拷贝fd到内核态，返回时内核态拷贝到用户态。

上限为什么要设置1024？？  内核拷贝和用户都需要拷贝和轮训。
使用top ， ps就能查看进程。

支持阻塞操作的设备驱动实现一个队列，所有fd注册__pollwait回调函数，全部做一次poll挂入各自队列（若设备没有就绪，没有把进程挂入设备等待队列，
若设备就绪，则看是否有fd需要读取，没有则进程挂入设备等待队列），有限时进入睡眠再重复poll。
select巧妙的运用了等待队列，当有事件触发，内核态拷贝到用户态，然后进行用户操作。

poll优点:不需要频繁修改event，仅仅第一个调用的时候拷贝，返回时候修改revent即可，pollhup（是什么？） ， 
上限很大 ，需要把poll_fd拷贝到内核一次。
每个fd调用poll函数，每个不同的fd调用不同的设备poll，每个poll都调用自己设备的回调函数，把进程挂入到各自设备队列中去，
当设备收到数据后，唤醒等待队列的进程。
缺点：内核和用户都需要遍历

select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，
而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次 ??  //http://www.cnblogs.com/Anker/p/3265058.html

epoll优点：创建事件表，不需要频繁拷贝数据，返回就绪个数 ， 加入到event中，不需要轮询。 epoll_wait()是阻塞去等待
同一个描述符，会一直通知，直到你消费为止（LT水平触发 , 电平触发）   
1.使用mmap 2.红黑树  3.rdlist
给每个fd挂一个callback函数。设备驱动到网卡->callback添加到双链表中(通过回调函数避免循环遍历)，并发写，
就必须上锁，使用自旋锁（在内核使用的特别多）
缺点：如果都是活跃链接（发送接收活跃）大于90%时候，select，poll比epoll高效很多，不需要像epoll频繁callback。

每次调用poll系统调用，操作系统都要把current（当前进程）挂到fd对应的所有设备的等待队列上，可以想象，fd多到上千的时候，
这样“挂”法很费事；而每次调用epoll_wait则没有这么罗嗦，epoll只在epoll_ctl时把current挂一遍（这第一遍是免不了的）并给每个fd一个
命令“好了就调回调函数”，如果设备有事件了，通过回调函数，会把fd放入rdllist，而每次调用epoll_wait就只是收集rdllist里的fd就可以了



互斥锁，一般不进入忙等待，若线程没有占有锁结构，则挂起阻塞。
自旋锁一般用于多核CPU，一般当在CPU中进行忙等待，直到获取到锁结构 ，自旋锁不会引起调用者睡眠，所以公共资源的利用率高。
但是自旋锁会一直占用CPU，如果不能尽快得到锁，是的CPU利用率下降，自旋锁适用于锁使用者保持锁时间比较短的情况下。
被自旋锁保护的临界区代码执行时，它不能因为任何原因放弃处理器。

软中断：由程序进行发起，只有当前运行程序可以发起，调用内核中断程序（一般是IO请求）也只有当前正在运行的代码（或进程）才会产生软中断。
硬中断：由硬件发起，直接中断CPU，调用内核中断程序（比如时钟中断）， 硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。
每个设备或设备集都有它自己的IRQ（中断请求）

LT , ET应用场景是什么？？  ET用在及其高并发的情况
进程，线程，协程（查） ，纤程 ，超线程 ， 用户线程 ， 内核线程？？

协程：一种用户态的轻量级线程，子程序就是协程的特例，因为是一个协程，所以不需要锁结构，协程运行一部分A，再接着运行一部分B，
ABABABABA来回跳转运行，避免了线程的切换抢占过程。

mvcc + 协程 ？？
多版本并发控制

c++11支持哪些特性？？
1.增加了auto编译推演类型 ， 而且使得在模板推演时刻，可以得到模板的特定类型，不需要再多传递一个类型参数。
2.增加了decltype使我们得到变量类型，可以在确定返回值时使用，得到特定返回值得类型。
3.增加nullptr为了解决NULL和0的二义性。
4.简化for循环，for (auto p : m)
5.新增加了lambda表达式  ??
6.新增了make_tupleN元组的概念，新增变长参数模板更简单实现print
7.使用更加优雅的初始化方式，比如：vector<int> arr{1 ,2 ,3} ; ??

windows的网络模型有哪些？？(select iocp 信号驱动 阻塞和非阻塞) 
iocp：io完成端口（队列），是windows提供的异步io机制，内核开辟多个线程，轮流执行在公共消息队列中取得数据，这个作为交换的队列就叫做完成端口
完成端口基于Overlapped机制（重叠结构），表示执行I/O请求的时间与线程执行其他任务的时间是重叠(overlapped)的。
完成端口可以理解为一个内核对象（与handle类似） ，将socket和完成端口绑定，工作线程来解决完成端口中的读写操作
http://blog.csdn.net/beyond_cn/article/details/9336043

用户数据的拷贝与用户和内核数据的拷贝对比？？

TCP提供：1.滑动窗口 2.缓存 3.超时重传 4.选择确认ACK 5.流量控制 6.拥塞控制

TCP可靠性：1.全部到达，有序到达（序列号） 2.SYN = 1(同步)建立同步链接
1.client  SYN_SEND   ->SYN(同步请求) + 序列号（服务器同步开始位置X）
2.server  SYN_RECV   ->SYN(同步请求) + ACK + ack(client序列号 + 1) + 序列号（服务器起始Y）


滑动窗口为了充分利用网络带宽 ，send存在缓冲区来保障滑动窗口的大小。防止丢失，内核直接发送出去。
把发送了的，但没有确认的保存在内核buff中。（滑动窗口的大小）

只有通过accept处理过的描述符，才能进行读写操作，读取到源端口源IP
listen创建一个句柄，里面映射到一个内核链表中，内核负责监听，accept从listen取出一个目的IP/端口，与自己的ip/端口绑定创建一个fd
accept返回值标识了唯一链接，四元组标识唯一链接（IP:PORT(本地)   IP:PORT(目的)）

四次挥手过程中，为什么会出现TIME_WAIT意义有哪些？？
1.可靠地实现TCP全双工连接的终止 ， 如果A端不维持TIME_WAIT状态，而是处于CLOSED状态，那么A端将响应RST分节，B端收到后将此分节解释成一个错误。
2.允许老的重复分节在网络中消逝 ，维持两个MSL保证旧分组已经消失在网络中。
如果服务器中多个链接都处于这个状态，我们应该怎么做？？
具体现象是对于一个处理大量短连接的服务器,如果是由服务器主动关闭客户端的连接,将导致服务器端存在大量的处于TIME_WAIT状态的socket, 
甚至比处于Established状态下的socket多的多,严重影响服务器的处理能力,甚至耗尽可用的socket,停止服务. 应该解决重用时的延迟使用时间。

CLOSE_WAIT 根据TCP状态机，服务器端收到客户端发送的FIN，则按照TCP实现发送ACK，因此进入CLOSE_WAIT状态。
但如果服务器端不执行close()，就不能由CLOSE_WAIT迁移到LAST_ACK，则系统中会存在很多CLOSE_WAIT状态的连接。
此时，可能是系统忙于处理读、写操作，而未将已收到FIN的连接，进行close。此时read收到FIN会返回0 。
可以通过修改内核参数，修改默认超时时间，发起probe判断链接是否失效。

三次握手为什么需要第三次？？  四次挥手为什么是四次，而不是三次？？
close是否真正触发四次挥手？？close用于断开链接
shutdown与close的区别和联系？？
如果有多个进程共享一个套接字，close每被调用一次，计数减1，直到计数为0时，也就是所用进程都调用了close，套接字被释放。
在多进程中如果一个进程中shutdown(sfd, SHUT_RDWR)后其它的进程将无法进行通信. 如果一个进程close(sfd)将不会影响到其它进程.
close可以理解为是引用计数的方法，而shutdown是真正的强制关闭。

用于网络接收发的函数有几组？？read，write ； send ， recv ； sendto ， recvfrom ； 
splice零拷贝是什么？？  
零拷贝消除系统内核中不必要的拷贝过程，和通讯协议的层次处理，不需要在用户态为数据申请buffer，也就是不会产生用户态、内核态之间的数据拷贝
相比于read和write需要在用户态使用buff
进程概念，创建方式，基本状态，状态流转的过程？？

不同的锁，无锁队列，自旋锁，意向锁 ，CAS算法，乐观锁悲观锁？？？？
CAS实现乐观锁算法，（比较与交换），CAS有三个操作数，旧值，新值和内存值，当旧值和内存值相等时，被理解成没有被改变，则可以把新值替换内存值，
否则放弃这次操作。无锁环境就需要借助volatile原语，保证线程间数据可见（共享） 。
CAS第一个问题是会导致“ABA问题”。
通过版本号（时间戳）来解决ABA问题的，我们也可以使用版本号（verison）来解决ABA。
即乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行+1操作，否则就执行失败。

意向锁可以理解为试图加锁的概念，IS,IX，X,S锁，锁可以加在兼容的锁之中而不产生冲突。
乐观锁总是认为别人不会修改数据，所以不上锁，在更新的时候判断有无人更新数据，如果已经被更新，则失败，使用版本或者时间戳进行更新。
悲观锁总是认为别人会修改数据，所以操作之前上锁。

像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，
上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。

http://tech.meituan.com/cache_about.html  //缓存


3/26日
进程：执行中的程序，可执行的文件装入到内存中，获得CPU。（可执行权限需要看是否有X权限）unix不是以扩展名表示而是X，windows是通过扩展名exe
特性：唯一的PID->对应一个PCB->task_struct，动态性(按需申请，释放)，独立的内存地址空间（32位4GB），进程共享所有物理资源（寄存器等等）
，在进程运行时，却又是独享物理资源

tast_struct中有一个fs_struct文件描述符表，进程间独立维护，open返回时，就把fd的地址和进程进行关联保存在fs_struct中，不用open的fd，不能去访问
文件资源，因为这个fd没有被挂到fs_struct链表中

CPU只认识0101，不同文件需要下载各自的转化器，所有字符都不需要存，不需要存储组合信息，只需要有字符的解码过程。

进程的状态？？
就绪，运行，挂起，阻塞。当阻塞的程序较多时，内存位置有限，将阻塞的进程进入挂起状态，空出内存，将新程序建立，进入就绪状态。
进程间私有的：数据是私有的，在运行的时候，堆和栈独享(可重入)

进程必须具有可重入的功能，在进程运行期间需要什么数据，就向内核进行申请。
pid = 0 idle(当某个CPU没有东西运行时)的进程号，第一个进程在一个特殊扇区写死的（C盘和sda）,开机后把代码拉其起来，再调用fork创建1号进程

内核初始化过程中，通过静态定义构造出了一个task_struct接口，取名为init_task，然后在内核初始化的后期，通过rest_init()函数新建了内核
init线程.kthreadd内核线程，变为所有内核态其他守护线程的父线程。init线程最终替换执行/sbin/init进程，然后演化成根进程。
kthraadd就是管理和调度其他内核线程kernel_thread，执行kthread函数，维护全局kthread_create_list中的kthread，调用kernel_thread都会加入到这个
链表之中，所以内核线程都直接或间接以kthreadd为父进程。

pid=0的进程调用 cpu_idle()演变成了idle进程 ，然后加入CPU进行周期循环操作cpu_idle_loop()。init_idle_bootup_task, 让init_task进程隶属到idle调度类中。
即选择idle的调度相关函数。
cpu_idle_loop()：目的就是节能和低退出延时，主处理器上的idle由原始进程(pid=0)演变而来。从处理器上的idle由init进程fork得到，但是它们的pid都为0
，dle进程为最低优先级，且不参与调度，只是在运行队列为空的时候才被调度。Idle循环等待need_resched置位。默认使用hlt节能。
http://blog.csdn.net/gatieme/article/details/51484562

除了0号进程，其他进程都需要进程fork产生，既然创建子进程，都需要进程回收他们，就应该等待子进程回收他们，如果不删除，子进程依然占用资源
在32位系统上，每个内存页4KB ，内核地址申请2个内存页，当一个进程结束后，task_struct还给slab(而不是内核操作系统)，slab会把核心结构体进行缓存。

1号进程？？查查

并行：物理上的概念，8个CPU同一时间上最多8个进程跑
并发：逻辑概念，得益于CPU的调度算法，用户再同一时间无感知快慢，8个CPU跑20个程序。
函数返回值的问题，主函数return 0 会调用exit去清理空间。

命令：rdd  source  bash  fdisk(查看挂载几个盘)  stat  which(可执行路径)
source 命令  执行一个文件，使得一个脚本运行，不需要修改权限
运行脚本  (bash) ./my.sh  sh my.sh    bash my.sh

//vfork保障子进程先运行，父进程后运行
int i = 0 ; int max = 0 ;
pid_t pid = fork() ;  //fork让父进程先运行,把父进程先加入到时间片中，父子进程优先级一样，但是时间片递减
if(pid == 0){ for ( ; i < max ; i++){printf("i");}}
else {for 打印 i }
01234567890123456789  时间片问题(毫秒级别)

fork 复制父进程的方式，产生一个子进程(copy on write)，共享全局变量和描述符(socket，文件，信号)
返回值，调用一次返回两次，父进程返回子进程PID，子进程返回0，-1表示fork调用失败

僵死进程：子进程结束父进程没有进行资源回收，使得子进程虽然已经释放空间，但是还保留着进程pid，进程可以调用wait回收或者当父进程结束时，
接管的进程会回收父进程以及僵死进程。
当父进程结束，而子进程还处于运行状态时(孤儿进程)，会有init进程或者同组进程进行接管，直到子进程退出。

fork->do_fork->copy_process之后的步骤，分配pid的实现，申请tast_struct结构体的过程，用什么函数申请的，
判断用户的进程的上限值（安全检查），如何做到让父进程优先运行？(必查)

从do_fork函数开始学起，vfork，clone都底层调用do_fork

管道在内核，都需要从用户态拷贝到内核态，内核态拷贝到用户态，开销比较大。mmap更加高效,克服了这个拷贝问题，在用户态进行拷贝。

线程的概念：轻量级的进程，进程中的一条执行路径，有自己的pid，共享进程的所有资源，每个线程运行期间，堆栈独立，如果线程不运行时，
线程会把资源释放出来，让给其他进程。  

pthread线程API需要查查？？？！！

用户线程：线程的创建调度回收，都是在用户态实现的，包括线程调度算法，内核没有意识到有线程存在
优点：1.线程的切换在用户态完成，不需要进入内核，节省了模式切换，用户到内核，内核到用户的开销。
2.调度算法可以由应用程序自己考虑，而且不会扰乱操作系统的调度器。
3.用户级线程可以在任何操作系统中执行，不需要对底层内核修改去支持线程。
缺点：1.当一个用户级线程执行系统调用时，进程中所有线程都会被阻塞
2.纯粹内核线程不能多CPU的技术，一次只能执行一个进程的一个线程

内核线程：线程创建调度回收都是由内核去完成。
优点：1.一个线程阻塞系统调用，其他线程不阻塞（锁不一定）
2.可以同时使用多CPU处理程序，运用多核技术
缺点：1.线程切换时需要调到内核的模式切换

当下需要运用多处理器，内核线程更符合时代，海量并发时，必须使用多核。pthread是内核线程

MIMD：多指令多处理器 ， 主从关系， SMP(对称多处理器)
主从关系：主处理器运行内核代码，一个CPU作为进程调度，控制所有IO和存储器资源，简单减少冲突
缺点：主处理器失败导致整个系统的失败。 主处理器完成所有调度和进程管理，出现性能瓶颈。

SMP：多个处理器都可以运行内核代码，多个处理器同时运行多个进程，有一级缓存，使用硬件解决高速缓存一致性问题

微内核：改变传统的层级分布内核，使用微内核来传递件间信息并且授权访问硬件，将以前大部分内核进程变成用户进程实现。
优点：提供了一致性接口，促进扩展性(都当成用户进程扩展)，有助于分布式，最小接口灵活性
缺点：性能瓶颈，构造和发送信息，接收应答并解码所花费的时间比进行一次系统调用的时间多。

互斥：对于多CPU实现互斥功能，使用testandset进行实现，因为是原子操作，只有那个获得变量为0的进程可以继续执行，其他的进程访问时已经变成了1，
所以进入忙等待，直到变成了0为止

信号量：信号量可以理解为特殊的信号操作，二元信号量只有01的区分，如果进程检查semWait如果为0 ， 则受阻，如果semSingal操作检查是否有受阻进程，有
就唤醒进程，没有就把值设置为1 ，直到有进程调用semWait才改变。都需要使用队列来保存正在等待的进程。使用testandset实现互斥操作(原子操作)

管程：
消息传递：对某个进程直接发送或者接收消息，有特定的格式。

Linux并发机制：管道，消息队列(类似信箱)，共享内存，信号量，信号
Linux内核并发机制:原子操作,自旋锁,信号量,

ps -eLf查看线程pid号

进程空间是独立的，但是当我需要调试你的时候，我可以访问你，而且是合法的，这个是怎么实现的呢？？
进程可以创建线程，线程也可以创建进程。

任务：
1.CPU密集型 ，做计算的类型多，数据处理运用CPU运算
2.IO密集型 ，不断磁盘读写，网络IO操作
多进程(多线程)需要利用多个CPU ，提高并发，因为里面的任务容易被挂起，当某个任务挂起时，还有其他进程进行服务。

读取内存比读取磁盘速度快10W倍.

Mysql里面存在了很多的多进程，进程池等等的模型的组合体

单进程：CPU密集型任务，纯内存操作，数据都在内存中，CPU处理，不需要产生IO等待，可以一直对外进行服务，
运用多进程会加大开销去维护进程的通信 ，redis(有中文注释版)的在大型互联网大量使用，在备份的时候会创建一个进程.
多进程:需要频繁等待IO ，进程意外退出不会影响其他进程。进程间通讯效率不高。强壮性 ，具有独立地址空间。当同时创建很多个进程的时候，不受控制
进程池:多线程创建消亡是重复性工作，代价比较大，进程池避免了多次的创建消亡的开销，

内核迁移：当某个CPU比较忙，其他CPU很闲，内核创建了一个线程维护这种情况，把压力大的CPU里面的队列迁移到别的CPU，当进程线程很多时，
内核迁移也会带有很大的开销，做负载均衡(迁移线程函数？)
http://blog.chinaunix.net/uid-26772535-id-3197182.html
http://www.xuexila.com/diannao/yingjian/cpu/613536.html

schedule(): 线程迁移是由有闲的CPU(哪怕是相对比较闲)，它总会执行schedule()，当自身CPU空闲时调用idle_balance()，分担忙碌的CPU
在进程睡眠和醒来这两个时间点检查CPU们的负载 ，出现负载不均匀的时候，从忙的迁移到闲的CPU队列中，move_tasks实现线程迁移
遍历迁移时，从子domain再到父domain，现在芯片内部迁移，再是芯片之间迁移。因为子domain通常都是在一个chip上，
任务的很多数据在共享的L2 cache上，为了不让其失效，有必要尽量让任务保持在一个chip上。

try_to_wake_up():决定进程运行时选择在哪个CPU上，如果目标处理器负载非常小，把进程从源移到目标处理器中
单线程：
多线程:需要频繁等待IO ，当线程意外消亡会影响其他线程。会出现线程安全问题，但是线程通讯高效，当线程需要多个同步问题，当同时创建多线程时，
CPU压力很大。 但是可以规避一些线程意外

线程池：这是可以使用线程池减轻创建压力。对于一些批量的任务，往往会用到线程池，比如微信红包的定时发还

进程池线程池为多大：N(2 < N <= 6) * CPU

开发者需要对线程安全问题有解决。什么样的异常会波及其他线程退出？？如何维护强装性。线程安全？？
而全局变量、局部静态变量、分配于堆的变量都是共享的。在对这些共享变量进行访问 时，如果要保证线程安全，则必须通过加锁的方式。
所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不 用考虑同步的问题。

单进程最大线程数一般为1024(应该被线程栈大小限制8M？？)(但是实际测试为10000+) ， 进程应该被pid_t限制，以及系统的默认值。

内存策略：读取策略(请求或预读) ， 放置策略(段页式) ， 替换策略(四种替换)，驻留集(固定，动态) ，清除策略(请求或预读)

伙伴系统：每次分配时都可以把当前内存分配成为两个相同大小的伙伴，回收时可以合并相同等级的伙伴，类似于二叉树
进程位置不是固定的，当每次被换入或者移动时，会被改变

段页式：虚拟地址 = 段号 + 页号 + 偏移量，先通过段号寻找页目录地址，页号得到页表位置，页表内容+偏移量得到物理地址。
每个段都分配一个页目录。

多种页面分配策略：
1.读取策略：(请求式)分页，当读取到页面第一个单元时，发现缺页中断读取页进入内存，进程第一次启动时，会发生大量缺页中断。预约式，提前读取。
查查核心的线程函数？？
2.替换策略：基本算法 
最佳：下次访问距离当前时间最长的页被替换。 最近最少：替换距离当前最远的页。先进先出。
时钟策略：给每一个页加入一个使用位01表示，操作系统遇到0位时，将页进行替换，遇到1时，改成0，寻找下一个页，如果全为1，则进行第二轮替换。

页缓冲:当一个页面要被替换时，将其放入空闲列表或者修改列表中，如果进程切换的页面是空闲列表或者修改列表中，返回驻留集。而且修改列表中的回写
也实现以簇的方式写回，而不是一次只写一个页。

操作系统分配页方式：（驻留集大小）
固定分配策略：分配一定数量页，当需要新页时，替换进程其他页。可变分配策略：允许进程拥有页面数不一定。
替换可以在局部(进程内部的页面) , 也可以在全局(所有空闲空间)，进行页面的替换。

linux内存分配，虚拟寻址使用三成索引，但是中间层一般不使用，内存分配使用伙伴算法，页替换使用时钟替换。
内核内存使用slab缓存机制实现分配小块内存，类似于链表的伙伴算法，维护一个链表，用伙伴算法分配。

数据备份是企业级的关键，分布式存储，企业级的算法，数据的一致性

memeache使用多线程

东东链接：
http://blog.csdn.net/zhangskd/article/category/3263315
http://blog.csdn.net/column/details/zhangskd.html
http://blog.csdn.net/zhangskd/article/category/902074

预习知识：
可靠UDP：
我们只需要提供一个重传机制即可。在这我实现了一个简单的可靠udp协议，这个协议为每一个发送出去的udp数据包分配一个包id，
每次接收方收到一个数据包时，都要回应发送方一个ack对应这个包id。协议通过这种确认机制来保证接收方能收到发送方发出的udp数据包，
在发出的时候，发送方应该设置一个计时器，超时的话会重传数据包。

UDP打洞原理：
两个客户端向服务器发送数据，服务器交换了客户端的数据(得到IP和port) ，下一回客户端就可以根据服务器给定的ip和port进行交换数据，而不通过
服务器进行转接


4/3日
//查查fork函数调用步骤以及实现!!//3/26日的任务！
fork vfork clone  fork-->_clone 可以通过这个函数自己实现线程

do_fork  -> copy_process 调用kmalloc(在内核申请内存) 给予PCB(初始化,消亡时放回slab)  4KB * 2的页面初始化(延迟  fork返回并未全部建立完成映射)
内存是操作系统核心资源，fork完成时没有全部建立映射，后续实现按需分配(比如mm，fs在运行时不断修改变量)
->QOS判断资源校验是否合格 -> 优先级设置 thread_info task_struct state ->alloc_pid申请PID  
->设置当前子进程不可运行加入到队列中(父进程一直运行，子进程就绪调度)

线程底层调用和fork一样，就是在_clone中设置了不同的参数(设计了不同标志位)
fork一开始是全复制需要让父进程先运行，子进程再进行，vfork优先让子进程实现，子进程运行结束时，发送一个信号调用父进程 ，fork进化成为(COW) ,

pthread_create是一个库，通过这个库调用内核，_clone

进程组，后台进程，守护进程(守护进程的创建？) 前台：有交互，可以看到进程运行状态，接收用户的输入，依赖于某个终端
后台进程：不输出到终端放到内存或者磁盘。如何实现后台进程？ 后台进程可以用到进程组的概念 (理论到实现)

进程组是使一群进程有关系，不然当并发多个进程时，需要一一对其杀死，如果有进程组，则可以将关联的进程全部一下杀死。
一个会话又可以包含多个进程组。一个会话对应一个控制终端。
后台进程:运行在后台，但是依然是继承终端，终端为其父亲

守护进程:是后台进程，但是成为进程组组长，会话组长，和终端失去联系
1.在后台执行，方法是创建子进程，父进程退出，则子进程在后台运行。
2.脱离控制终端，脱离会话和进程组。调用setsid()让进程脱离
3.可以禁止进程重新打开终端if(pid=fork()) exit(0); 退出第一子进程使用第二子进程工作(脱离中断控制权)
4.关闭从父进程继承而来的文件描述符。
5.改变当前工作目录，一般更换到根/目录上。 6.设置掩码。7.设置处理信号
可以实现日志
http://blog.csdn.net/liangxanhai/article/details/7752898

用代码实现，看看主函数的父进程ppid是不是终端？
创建的子进程时间片会比父进程小
int arr[5] ar , &ar[0] , &ar 的地址  都表示相同的地址
sysctl ulimit quote ??   //端口改成80端口是否可以绑定
申请内存API  tcmalloc  jemalloc  ptmalloc 三款企业级别API查查？？  QOS服务质量保证？？//资源和权限的判断

//malloc实现 http://blog.csdn.net/msdnwolaile/article/details/51695361

Ptmalloc:使用主从分配，线程需要分配时，找到没加锁的分配区。 http://blog.csdn.net/phenics/article/details/777053
获取分配区加锁(arena)-> fast bin-> unstored bin-> small bin->large bin->top chunk->拓展堆 ->mmap(大内存) 
线程没有独立的cache，从多个分配区寻找一个为加锁的获取内存，有128个bin，前64为小bin，后面为大bin，每个bin有一个chunk双向链表，指针在空闲时
存放在数据区中
缺点：每个arena内存不能交替使用，而且每次分配内存都要额外8个字节内存(前一个chunk大小，当前chunk大小以及标志位3个，后一个chunk大小)

tcmalloc对大对象使用了细粒度？？ 
细粒度：就是划分出很多个对象
tcmalloc:tcmalloc特别对多线程做了优化，对于小对象的分配基本上是不存在锁竞争，而大对象使用了细粒度、高效的自旋锁（spinlock）。
分配给线程的本地缓存。线程级别cache和进程级别cache实际上就是一个多级的空闲块列表（Free List）。
给每个线程分配一定空间的cache(Thread-local free list)，线程小对象在cache中分配，当cache空间不足时，从进程cache(Heap free listen)中分配大对
象，如果进程cache为空，则系统调用(mmap,brk) (Page array)分配连续空间加入到进程cache中。
tcmalloc每次申请是动态调整的，小内存：线程缓存队列->中央堆->中央页分配器  大内存：中央堆->系统请求

Jemalloc：对于小内存使用线程cache，然后再分配区bin(bin加锁) ， 再问系统要。 对于中等内存：分配bin->问系统要。大内存：使用mmap组织多个chunk
使用全局红黑树进行管理，使用meta记录的很多状态，结构相对之前复杂

异常处理因为用户态没有进行处理，抛给了内核才出现中断。 
goto 实现的是一个跳转指令jmp，跳转到指定的地址。
assert主要实现了什么？？   使用宏实现了一个逻辑关系，如果表达式为0，则调用abort()中断程序，打印程序信息。
http://blog.csdn.net/liangkaiming/article/details/5899655

wait(status)为阻塞，等待子进程退出，status可以保存子进程退出的状态(是否正常退出等) ，可以通过多个宏来解释status
waitpid(pid , status , option) 可以等到任意子进程，-1等待任一，0等待同组，>0等待PID值，<-1等待绝对值，option可以选择设置非阻塞
返回值：正常返回则子进程ID ，非阻塞时如果无子进程退出(返回0) ， 错误时返回-1

核心命令：top->1 C P   htop  iotop(看io使用情况)   dd快速创建大文件  -->/dev/zero  /dev/NULL
ps -ef等等 看看命令本身的结果
kill 杀进程  pkill killall 
调试进程 strace -p 调试内核调用 

netstat 获取当前所有网络连接状态(状态)  可以看到三握手四挥手
netstat -p 8080  找到端口被哪个进程使用 
tcpdump 获取任何一个socket的流入流出数据(数据)

ip route  ifconfig ifdown  ifup   选择性关闭网卡 重启网卡
vmstat free  iostat 内存相关  

TCP打洞
TFO：transport fast open 快速打开一个TCP连接，实现在三握手时就可以发送数据 ->http ->web
session(服务器) 会话 -->token(令牌) 复用通道  
cookies把用户的信息保存在本地


linux 在线阅读内核代码地址：http://lxr.free-electrons.com/
http://blog.csdn.net/eastmoon502136/article/details/8711104  这个链接里展示的内核代码组织结虽然“过时”了，
但是这种学习方法大家需要借鉴------ 自我理解+笔记（包括图文信息去记录）
源代码文件较大，我就不上传到群里了，有需要的可以去下面这个地址下载：https://www.kernel.org/pub/linux/kernel/v2.6/ 2.6.3.x 都可以
http://download.csdn.net/download/xiebaoyou/7017755   注释版内核代码
http://download.csdn.net/user/xiebaoyou

4/9日
进程状态R(运行) Z(僵尸) S(可中断Sleep) D(不可中断S)  T(暂停)  t(trace)

调试信息修改任何变量的值：_clone(trace)设置可跟踪，gdb就可以修改设置了trace的子进程，这就是内核源码中跟踪子进程的含义
gdb各种命令实现的原理？？ next等等，如何跟踪等等问题？？
gdb无论是远端还是本地都调用了ptrace系统调用ptrace系统调用提供了一种方法，让父进程可以观察和控制其它进程的执行，
检查和改变其核心映像及寄存器。主要用来实现断点调试和系统调用跟踪 
建立调试关系：1.fork+exec使得进程在创建的时候，就是被gdb调用fork出来再执行自己的程序。2.attach将gdb关联到正在执行的进程中去。
断点原理：就是在指定的位置插入断点指令(使用 int3进行替换保存)，当被调试的程序运行到断点的时候，产生SIGTRAP信号(被子程序得到，gdb也得到)。
该信号被gdb捕获并进行断点命中判定(gdb保存一个链表进行断点对比)，当gdb判断出这次SIGTRAP是断点命中之后就会转入等待用户输入进行下一步处理，否则继续。 
单步原理:直接由ptrace中的参数实现

goto和return的区别？？
ls ->list   -l(list)  -a(all)    -i(inode)   -h(hide？)
-rw-r--r-x  当前用户，同组(非当前用户的)，其他
mkdir 1/2/3 -p   cd  .(当前目录，文件名前表示隐藏) ~(家目录/home/user)  |(管道)  ||(表示或)   cd d1 || pwd   cd d1 & pwd(后台再显示)  cd d1 && pwd
cd  d1 && pwd || touch r1 && ls输出是什么？？      #命令行的注释    ;一个命令的结束命令依次被执行   `命令？？
chmod change mode    whoami  查看当前工作的是谁   查询脚本运行方式？？(67种)
chown change owner(修改当前文件拥有者或者组拥有者)   chown -R root1:jake(主人：组) dir  (递归修改)
cp r1 d1   拷贝r1进入d1   cp d1 d11 ？？对文件和目录的理解
mv rm pwd 打开文件方式 cat(tac反着输出) more less head tail vim vi
useradd在Ubuntu下不能在home目录下创建同名目录，没有设置密码，这个用户是不能登录的
adduser/在home目录下创建同名目录，提示输入密码，更加友好

UDP:
ifconfig MTU 1500
一般避免路由器拆包   粘包?? 

RUDP实现可靠的算法，使用TCP思想，使得UDP可靠

quic 谷歌实现的加速和可靠版UDP ????

UDP特点：
无连接，快速，单播(广/多/组) 广播和多播时使用D类地址  广播给当前所有能接受到当前能接受到的路由器发送，走进范围内都能接收到。
多播：明确指定哪些能收到分组，对应服务器收到
DNS，DHCP使用UDP特性
数据报
不可靠，无确认，无序，丢包
单个包大于TCP
KCP源码？？在群里 github链接 star 1K(火) fork(1K)   https://github.com/skywind3000/kcp
KCP为流速设计，就像冲刺的小溪，RTO(超时重传1.5倍) ，选择重传(只发送丢失包) ， 快速重传(某包后面包ACK两次，重传) ，UNA(编号之前已经收到的包)，
设置正常模式和快速模式

ping ICMP(网际层) 跳跃过传输层 传输层上是lib库再到应用层
tcpdump将网络中的传输数据包截取出来提供分析。

微信使用的是TCP，我已经发送了，对方接受到了信息，但是微信提示没有发送成功。
TCP可以延迟确认，保证整个网络可用(push)
UDP更偏向于poll的方式

SSL  TSL  

CDN(contant delivery network)，内容分发网络，CDN的基本原理是广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中，
在用户访问网站时，利用全局负载技术将用户的访问指向距离最近的工作正常的缓存服务器上，由缓存服务器直接响应用户请求。
使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。

https://qifuguang.me/2017/03/25/%E7%9C%8B%E5%AE%8C%E8%BF%98%E4%B8%8D%E6%87%82HTTPS%E6%88%91%E7%9B%B4%E6%92%AD%E5%90%83%E7%BF%94/
实现四层内容来保障安全：
1.安全数据传输(加密方式对称不对称，使用对称加密，如何传递密钥)
2.安全传递密钥(非对称加密算法，传递公钥，出现中间人攻击)
3.安全传递公钥(数字证书)
4.安全传递证书(证书内容与签名是否匹配)

一个电脑能链接多少个客户端？？  链接客户端的个数没有上限，fd上限来限制，只要高并发实现的好，一台pc可以同时支持非常多的并发。

分布式雏形：
生产者生产了数据到队列之中时，可以用push(有消息就给消费者)或者pull(有消息后，消费者主动请求，给予消息)两种不同得到生产者的信息。
push和pull两种方式的优缺点有什么？？        http://blog.csdn.net/pi9nc/article/details/27714745
push(消息产生就发送):实时，可能下游消费者消费不完，信源任务重，没有跟踪状态，要求对方在线才能传输
pull(产生后等待请求):延时(及时性差)
设计中可以使用push小数据通知，pull拉取大数据

订阅与发布:朋友圈      假设法和反证法
消息的撤回实现，可以在本地进行屏蔽而不是
先发消息，再向服务器pull
索引结构(消息ID)？？保存3~5份
uuid全局唯一，IP(多台服务器) + pid/tid(多进程) + time(时间戳) + rand (消息进行唯一标识)
消息设置成全局唯一，如何确定用户哪些数据读了哪些没读？(TCP序列号工作原理,序列号机制怎么做？)
服务器是做为中转，需要在用户层解决对方是否收到数据，若没收到，则会出现(对方未接受的情况)，使用序列号进行确认，使用私有的序列号，而且不能回退，
因为序列号对应了一个消息数据(群发和单聊)



4/16日

hash的使用？？DAU统计  set(集合，底层红黑树)  map(键值对)  c++ find函数的使用  ？？  动态规划再认真看看
服务器异常崩溃TCP链接的状态：http://www.cnblogs.com/yuxingfirst/archive/2013/07/03/3170333.html
1.服务器终止进程(发送FIN) 2.主机崩溃(客户端保活，或者数据不可到达错误终止) 3.服务器崩溃后重启(响应RST)  4.服务器主机关机(SIGTERM , 然后再杀死)


无状态性：每次请求都是独立的，执行情况和结果与前后无直接关系。

状态码：2XX系列：代表请求已成功被服务器接收、理解、并接受。这系列中最常见的有200、201状态码。
3XX系列：代表需要客户端采取进一步的操作才能完成请求，这些状态码用来重定向，后续的请求地址（重定向目标）在本次响应的 Location 域中指明。
这系列中最常见的有301、302状态码。4XX系列：表示请求错误。代表了客户端看起来可能发生了错误，妨碍了服务器的处理。常见有：401、404状态码。
5xx系列：代表了服务器在处理请求的过程中有错误或者异常状态发生，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理。常见有500、503状态码。

实模式：
1.使用率不高，内部碎片 2.安全性低
着色？？migration线程，实现线程的迁移？？
kernal_init()创建了migration线程。先调用migration_init()调用migration_call()参数不同，建立并且唤醒，register_cpu_notifier()将migration_notifier挂入
cpu_chain链表，cpu_up将其他CPU唤醒，CPU执行回调函数migration_call后，创建线程kthread_create(加入到kthread_create_list中),使得每个CPU都有一个mig线程(kthread_bind(p, cpu)),这样每个CPU都具有一个内核迁移线程


每个处理器都会创建一个watchdog线程，进行监视系统运行，如果每隔一段时间，watchdog没有被写入是数据(一分钟)，硬件watchdog会重启系统。
计数——溢出——触发，如果一定时间没有重新计数，则触发溢出时间

ksoftirq:每个CPU都有一个线程，只要有待处理的软中断(由softirq_pending()函数负责发现)，ksoftirq就会调用do_softirq去处理它们。通过重复执行这 样的操作，
重新触发的软中断也会被执行。如果有必要，每次迭代后都会调用schedule()以便让更重要的进程得到处理机会

init migration ksoftirq watchdog kthread？
mongoDB mmap  3G的映射？？ 用户地址4G理解，内存的延迟分配？？    
redis如何管理几个T的内存？？  集群的能力管理？？

集群：分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。
http://jiangzhi2013.blog.51cto.com/7150666/1222666

集群：高扩展，高可用(防单节点失效)，高性能(允许同时接入很多)。
负载均衡集群：负载尽量在集群中分摊处理。LVS(linux virtual server),用户只感觉到一个虚拟服务器，
负载均衡器的运行模式:
1.(VS_NAT)对内部节点进行封装，通过转换器传达，收发都经过转换器。节省IP，对内部进行伪装，但是效率低
2.(VS_DR)DR模式是这样工作的，当CIP访问VIP后，VIP把数据包通过DIP转交给RIP,RIP在收到数据包后通过网卡别名欺骗（节点的网卡配置别名，IP为VIP），直接用别名的VIP相应客户端，从而加快了回应速度，
也避免了Director成为地址转换的单点故障.目前主要应用的为DR模式的负载均衡.
3.(VS_TUN)隧道:调度器把请求报文通过IP隧道转发至真实服务器，而真实服务器将响应直接返回给客户，所以调度器只处理请求报文。由于一般网络服务应答比请求报文大许多，采用 VS/TUN技术后，
集群系统的最大吞吐量可以提高10倍。

IPVS:IPVS无法检查到请求的内容再选择服务器，这就要求后端服务器组提供相同的服务，不管请求被发送到哪一台服务器，返回结果都是一样的。但是，在有些应用中后端服务器功能不一，
有的提供HTML文档，有的提供图片，有的提供CGI，这就需要基于内容的调度 (Content-Based Scheduling)。

VPN原理？？全称为Virtual Private Network，译为无线虚拟专用网络，主要用于在公用网络上建立专用网络，进行加密通讯。
VPN隧道？？


内核如何切入切出如何保存数据？
设备驱动程序或者内核模块中动态开辟内存，kmalloc，vmalloc？？如何从物理拿到一个页面，normal和high在什么时候被分配？？
kmalloc分配物理地址连续的线性地址，可以用于DMA，vmalloc只是线性地址连续，物理不一定连续。
kmalloc是基于slab分配的，所以分配的是连续的物理内存，kmalloc能分配的大小有限,vmalloc和malloc能分配的大小相对较大
vmalloc可以分配线性地址连续，物理不一定连续的空间，因为内核分配很多小空间，不一定每时每刻都有连续的空间，优先分配zone_high空间。？？

page是描述一块物理内存的，tast表示的是虚拟的可以复用。
内核没有使用用户内存，只需要管理好每个tast_struct，就可以管理每个进程。

为了提高CPU的利用率，使用DMA-->isAISE(设备)
DMA:绕过cpu进行内存的读写，所以提供专门的内存进行读写，避免竞态，zone_DMA(16MB)
zone：zone_DMA(16MB),zone_nornal(16~896)映射到物理内存,zone_high(896~1G),内核内存可以使用的范围(1G)
每个zone使用zone_mem_map->page，使用伙伴系统管理page，再从伙伴系统中延伸出slab层，slab是伙伴系统的缓存，使得伙伴系统产生延迟合并
slab(内核缓存)里面又有full，partid，empty(内核) ，malloc(用户态)有自己的cache(pt，tc，je)，brk/mmap/unmap

为什么内存需要产生栈和堆？  编程需求，对于每种数据需要的使用周期不一样。
需要将知识成为体系，形成网状。。。

node(节点)：(x86只有一个node)每个CPU操作自己的内存，node->zone->三个zone_
buddy(伙伴):有6中大小 1 2 4 8 16 32，按照页面分配，适用于分配大内存的空间，使用位图数组进行标记，第一组标记自己，第二组标记比邻，依次类推，有10个数组
slab：在伙伴系统后又增加一层slab的缓存，适用于分配小内存的空间

CPU有三层cache

当下linux采用分页，端口号限制的是主动链接的个数，一个端口可以收到多个客户端，由fd绑定，管理多个客户端。

微信红包
1.用户的登录和注册(是否加密，如何防止截获)
注册：名字，密码，验证(邮箱，短信，拖拽，图(在客户端匹配)，随机，确定是人在操作)，加密发送服务器-->server
名字：格式：长度，字符(企业为什么不能输入特殊字符，和长度的限制)，唯一性(验证)
密码: 长度，格式(允许使用特殊字符)，强中弱的判断(如何识别一般)  使用正则表达式(会用，实现)
加密算法：AES,DES,RSA(实现SSH，动态令牌),SHQ,base64(代码混淆),MD5(看看),混合加密(可以替换其中几位，或者提出几位组合等等)，加密算法是不可逆的。
服务器端:数据传入是密文(校验的是密文不是明文)，数据库存入的也是密文

MYSQL:不能使用一个表进行操作，无法支持大量并发访问(7亿)，一般一个表大概在1000万到3000万(分库分表(时间，或者注册时间等冷热区分))
联合查找(笛卡尔)，join将有关系的表联合在一起，关系型，INNER JOIN（内连接,或等值连接）：取得两个表中存在连接匹配关系的记录。
LEFT JOIN（左连接）：取得左表（table1）完全记录，即是右表（table2）并无对应匹配记录。
RIGHT JOIN（右连接）：与 LEFT JOIN 相反，取得右表（table2）完全记录，即是左表（table1）并无匹配对应记录。

90%都在读，对读进行优化    route进行路由到正确的服务器
INNODB引擎:对MySQL实现了行锁
SQL：结构化数据
非结构：音频视频，没有任何结构的单纯文件

2.好友的管理，添加删除，查找
3.群的管理(群主，申请加入群，踢群退群，群发功能，红包的单发和群发(固定和随机算法？？)，红包的过期和退还，每个人只能抢每个红包又一次)
4.聊天，视频，音频

mysql表与表的关系，确认序号每次+1？？ 红包过期的实现

github：http://www.cnblogs.com/ssh-007/p/6637055.html
http://blog.csdn.net/steven6977/article/details/10567719